{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ddafcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions._utils_ import *\n",
    "from functions.data_loader import processDFA1\n",
    "\n",
    "CURRENT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f992f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = os.path.join(CURRENT_DIR, \"models\")\n",
    "models = {}\n",
    "\n",
    "for file in os.listdir(models_dir):\n",
    "    if file.endswith(\".onnx\"):\n",
    "        key = file.split(\"_\")[0]  # Take index 0 after splitting by \"_\"\n",
    "        models[key] = {\n",
    "            \"model_path\": os.path.join(models_dir, file),\n",
    "            \"meta_path\": os.path.join(models_dir, file.replace(\".onnx\", \".json\"))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c257223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = (600, 1500)  # Raman region of interest\n",
    "labels = [\"benign\", \"cancer\"]\n",
    "# https://ramanspy.readthedocs.io/en/latest/preprocessing.html\n",
    "# https://www.nature.com/articles/s41377-024-01394-5\n",
    "preprocess_steps_test = [\n",
    "    rp.preprocessing.misc.Cropper(region=region),\n",
    "    rp.preprocessing.despike.WhitakerHayes(),\n",
    "    rp.preprocessing.denoise.SavGol(window_length=11, polyorder=3),\n",
    "    # rp.preprocessing.baseline.ASPLS(),\n",
    "    rp.preprocessing.baseline.ModPoly(tol=0.001),\n",
    "    # rp.preprocessing.normalise.Vector(),\n",
    "    SNV()   # Use SNV normalization as in the Readme\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f13c51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://datadryad.org/dataset/doi:10.5061/dryad.cjsxksn3p\n",
    "PROSTATE_CANCER_DATASET_PATH = os.path.join(\n",
    "    CURRENT_DIR,\n",
    "    \"test_rawdata\",\n",
    "    \"A1-dataset_prostate_cancer\",\n",
    "    \"Benign_vs_Cancer.pkl\",\n",
    ")\n",
    "\n",
    "load_dataset = RamanDataLoader(PROSTATE_CANCER_DATASET_PATH)\n",
    "rawdata = load_dataset.data\n",
    "\n",
    "# create a subset for a given key value\n",
    "chum_df = rawdata[rawdata['Cohort'] == 'CHUM']\n",
    "uhn_df = rawdata[rawdata['Cohort'] == 'UHN']\n",
    "chuq_df = rawdata[rawdata['Cohort'] == 'CHUQc-UL']\n",
    "print(rawdata.shape, chum_df.shape, uhn_df.shape, chuq_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a501f998",
   "metadata": {},
   "outputs": [],
   "source": [
    "chumDF_benign = RamanPipeline().preprocess(\n",
    "    dfs=[processDFA1(chum_df[chum_df['Label'] == 'Benign'])],\n",
    "    label=labels[0],\n",
    "    region=region,\n",
    "    preprocessing_steps=preprocess_steps_test,\n",
    "    visualize_steps=False\n",
    ")\n",
    "\n",
    "chumDF_cancer = RamanPipeline().preprocess(\n",
    "    dfs=[processDFA1(chum_df[chum_df['Label'] == 'Cancer'])],\n",
    "    label=labels[1],\n",
    "    region=region,\n",
    "    preprocessing_steps=preprocess_steps_test,\n",
    "    visualize_steps=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a840f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "uhnDF_benign = RamanPipeline().preprocess(\n",
    "    dfs=[processDFA1(uhn_df[uhn_df['Label'] == 'Benign'])],\n",
    "    label=labels[0],\n",
    "    region=region,\n",
    "    preprocessing_steps=preprocess_steps_test,\n",
    "    visualize_steps=False\n",
    ")\n",
    "\n",
    "uhnDF_cancer = RamanPipeline().preprocess(\n",
    "    dfs=[processDFA1(uhn_df[uhn_df['Label'] == 'Cancer'])],\n",
    "    label=labels[1],\n",
    "    region=region,\n",
    "    preprocessing_steps=preprocess_steps_test,\n",
    "    visualize_steps=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4889b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "chuqDF_benign = RamanPipeline().preprocess(\n",
    "    dfs=[processDFA1(chuq_df[chuq_df['Label'] == 'Benign'])],\n",
    "    label=labels[0],\n",
    "    region=region,\n",
    "    preprocessing_steps=preprocess_steps_test,\n",
    "    visualize_steps=False\n",
    ")\n",
    "\n",
    "chuqDF_cancer = RamanPipeline().preprocess(\n",
    "    dfs=[processDFA1(chuq_df[chuq_df['Label'] == 'Cancer'])],\n",
    "    label=labels[1],\n",
    "    region=region,\n",
    "    preprocessing_steps=preprocess_steps_test,\n",
    "    visualize_steps=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a95956",
   "metadata": {},
   "outputs": [],
   "source": [
    "hirushu_dir = CURRENT_DIR + '/test_rawdata/Tamura/引き継ぎ/ヒルシュ'\n",
    "hirushu_dir\n",
    "\n",
    "normal_dfs = []\n",
    "window_size = 50\n",
    "for k in range(1, 4):\n",
    "    csv_path = os.path.join(\n",
    "        hirushu_dir, 'データ', 'merged_data_raw', f'Case{k}', 'normal', 'normal.csv')\n",
    "    loader = RamanDataLoader(csv_path)\n",
    "    df = loader.data\n",
    "    processor = RamanNoiseProcessor(df)\n",
    "    processed_df = processor.baselineAndGaussianNoise(window_size=window_size)\n",
    "    normal_dfs.append(processed_df)\n",
    "\n",
    "# Process Hirushu data\n",
    "hirushu_benign = RamanPipeline().preprocess(\n",
    "    dfs=normal_dfs,\n",
    "    label=labels[0],\n",
    "    region=region,\n",
    "    preprocessing_steps=preprocess_steps_test,\n",
    "    visualize_steps=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f76797",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_spectra = [uhnDF_cancer, chuqDF_cancer]\n",
    "benign_spectra = [uhnDF_benign, chuqDF_benign]\n",
    "test_spectra = [k[\"processed\"] for k in cancer_spectra + benign_spectra]\n",
    "true_labels = []\n",
    "for k in cancer_spectra + benign_spectra:\n",
    "    true_labels.extend(k[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33019d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in models:\n",
    "#     print(f\"Loading {model} model...\")\n",
    "#     model = models[model]\n",
    "#     svc_linear_onnx = ONNXModel(onnx_path=model[\"model_path\"],\n",
    "#                                 meta_path=model[\"meta_path\"],)\n",
    "#     break\n",
    "\n",
    "# if svc_linear_onnx.load_success:\n",
    "#     pred = svc_linear_onnx.predict(test_spectra, class_labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d413ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import onnxruntime as ort\n",
    "\n",
    "sess_options = ort.SessionOptions()\n",
    "sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
    "\n",
    "print(\n",
    "    f\"Total number of individual spectra in test_spectra: {len(true_labels)}\")\n",
    "visualizer = RamanVisualizer(None)\n",
    "\n",
    "# --- Prepare PCA input ONCE using the first model's axis as reference ---\n",
    "first_model_key = next(iter(models))\n",
    "first_model_info = models[first_model_key]\n",
    "onnx_model_instance = ONNXModel(\n",
    "    onnx_path=first_model_info[\"model_path\"], meta_path=first_model_info[\"meta_path\"], sess_options=sess_options, providers=providers)\n",
    "\n",
    "current_common_axis = np.array(onnx_model_instance.metadata[\"common_axis\"])\n",
    "current_n_features = int(onnx_model_instance.metadata[\"n_features_in\"])\n",
    "\n",
    "X_pca_input_list = []\n",
    "for s_container in test_spectra:\n",
    "    if s_container.spectral_data is None or s_container.spectral_data.size == 0:\n",
    "        continue\n",
    "    for single_spectrum_original_axis in s_container.spectral_data:\n",
    "        if single_spectrum_original_axis.ndim != 1:\n",
    "            continue\n",
    "        if len(s_container.spectral_axis) != current_n_features:\n",
    "            interp_spectrum = np.interp(\n",
    "                current_common_axis, s_container.spectral_axis, single_spectrum_original_axis)\n",
    "            X_pca_input_list.append(interp_spectrum)\n",
    "        else:\n",
    "            X_pca_input_list.append(single_spectrum_original_axis)\n",
    "\n",
    "if not X_pca_input_list:\n",
    "    print(\"No valid spectral data to process for PCA.\")\n",
    "else:\n",
    "    X_pca_input = np.array(X_pca_input_list)\n",
    "    current_true_labels = true_labels[:X_pca_input.shape[0]]\n",
    "\n",
    "    print(\n",
    "        f\"Generating PCA plot for all test data with {X_pca_input.shape[0]} spectra.\")\n",
    "\n",
    "    # --- Fit PCA ONCE ---\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X_pca_input)\n",
    "\n",
    "    # Save for later use in decision boundary\n",
    "    pca_fitted = pca\n",
    "    X_pca_input_for_boundary = X_pca_input\n",
    "    X_pca_for_boundary = X_pca\n",
    "    current_true_labels_for_boundary = current_true_labels\n",
    "\n",
    "    # Plot PCA (no decision boundary here, just data)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    unique_labels = np.unique(current_true_labels)\n",
    "    colors = ['royalblue', 'gold', 'red', 'green', 'purple', 'orange']\n",
    "    label_to_color = {label: colors[i % len(\n",
    "        colors)] for i, label in enumerate(unique_labels)}\n",
    "    for label in unique_labels:\n",
    "        idxs = [i for i, l in enumerate(current_true_labels) if l == label]\n",
    "        plt.scatter(X_pca[idxs, 0], X_pca[idxs, 1], label=label,\n",
    "                    color=label_to_color[label], alpha=0.7)\n",
    "\n",
    "    # Compute and plot centroids, and line between them\n",
    "    centroids = []\n",
    "    for label in unique_labels:\n",
    "        idxs = [i for i, l in enumerate(current_true_labels) if l == label]\n",
    "        centroid = X_pca[idxs].mean(axis=0)\n",
    "        centroids.append(centroid)\n",
    "        plt.scatter(\n",
    "            *centroid, color=label_to_color[label], edgecolor='black', s=200, marker='X', zorder=5)\n",
    "        plt.text(centroid[0], centroid[1],\n",
    "                 f\"{label} centroid\", fontsize=12, weight='bold')\n",
    "\n",
    "    if len(centroids) == 2:\n",
    "        plt.plot([centroids[0][0], centroids[1][0]], [centroids[0][1], centroids[1][1]],\n",
    "                 'k--', lw=2, label='Centroid Line')\n",
    "\n",
    "    plt.title(\"PCA of All Test Data\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec608f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Now show decision boundary and confusion matrix for each model ---\n",
    "for idx, (model_key, model_info) in enumerate(models.items()):\n",
    "    print(f\"\\n--- Processing Model (Line {idx}): {model_key} ---\")\n",
    "    print(f\"Loading model from: {model_info['model_path']}\")\n",
    "\n",
    "    onnx_model_instance = ONNXModel(\n",
    "        onnx_path=model_info[\"model_path\"], meta_path=model_info[\"meta_path\"], sess_options=sess_options, providers=providers)\n",
    "\n",
    "    if not getattr(onnx_model_instance, \"load_success\", False):\n",
    "        print(\n",
    "            f\"Failed to load model for {model_key}. Skipping decision boundary/confusion matrix.\")\n",
    "        continue\n",
    "\n",
    "    # --- Decision Boundary in PCA space ---\n",
    "    print(f\"Plotting decision boundary for {model_key}...\")\n",
    "    # 1. Create meshgrid in PCA space\n",
    "    X_pca = X_pca_for_boundary\n",
    "    x_min, x_max = X_pca[:, 0].min() - 2, X_pca[:, 0].max() + 2\n",
    "    y_min, y_max = X_pca[:, 1].min() - 2, X_pca[:, 1].max() + 2\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                         np.linspace(y_min, y_max, 100))\n",
    "    grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "    # 2. Inverse transform to original feature space\n",
    "    X_grid_original = pca_fitted.inverse_transform(grid_points)\n",
    "\n",
    "    # 3. Predict using ONNX model (expects list of arrays)\n",
    "    # If your ONNXModel expects a list of containers, you may need to wrap X_grid_original accordingly.\n",
    "    # Here, we assume it accepts a numpy array directly.\n",
    "    y_grid_pred = onnx_model_instance.predict_numpy(\n",
    "        X_grid_original, class_labels=labels)\n",
    "    y_grid_pred = np.array(y_grid_pred).reshape(xx.shape)\n",
    "\n",
    "    # 4. Plot decision boundary with PCA scatter\n",
    "    label_to_int = {label: i for i, label in enumerate(labels)}\n",
    "    y_grid_pred_int = np.vectorize(label_to_int.get)(y_grid_pred)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.contourf(xx, yy, y_grid_pred_int, alpha=0.15, levels=len(\n",
    "        labels)-1, colors=[label_to_color[l] for l in labels])\n",
    "    for label in np.unique(current_true_labels_for_boundary):\n",
    "        idxs = [i for i, l in enumerate(\n",
    "            current_true_labels_for_boundary) if l == label]\n",
    "        plt.scatter(X_pca[idxs, 0], X_pca[idxs, 1], label=label,\n",
    "                    color=label_to_color[label], alpha=0.7)\n",
    "    # Centroids and line\n",
    "    centroids = []\n",
    "    for label in np.unique(current_true_labels_for_boundary):\n",
    "        idxs = [i for i, l in enumerate(\n",
    "            current_true_labels_for_boundary) if l == label]\n",
    "        centroid = X_pca[idxs].mean(axis=0)\n",
    "        centroids.append(centroid)\n",
    "        plt.scatter(\n",
    "            *centroid, color=label_to_color[label], edgecolor='black', s=200, marker='X', zorder=5)\n",
    "        plt.text(centroid[0], centroid[1],\n",
    "                 f\"{label} centroid\", fontsize=12, weight='bold')\n",
    "    if len(centroids) == 2:\n",
    "        plt.plot([centroids[0][0], centroids[1][0]], [centroids[0][1], centroids[1][1]],\n",
    "                 'k--', lw=2, label='Centroid Line')\n",
    "    plt.title(f\"PCA + Decision Boundary (Model: {model_key})\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- Confusion Matrix Heatmap ---\n",
    "    pred_result = onnx_model_instance.predict(\n",
    "        test_spectra, class_labels=labels)\n",
    "    y_pred = pred_result[\"y_pred\"]\n",
    "    if len(y_pred) != len(true_labels):\n",
    "        print(\n",
    "            f\"Warning: y_pred and true_labels length mismatch for {model_key}. Aligning to shortest.\")\n",
    "        min_len = min(len(y_pred), len(true_labels))\n",
    "        y_pred = y_pred[:min_len]\n",
    "        y_true = true_labels[:min_len]\n",
    "    else:\n",
    "        y_true = true_labels\n",
    "\n",
    "    print(f\"Showing confusion matrix for {model_key}\")\n",
    "    visualizer.confusion_matrix_heatmap(\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        class_labels=labels,\n",
    "        title=f\"Confusion Matrix (Model: {model_key})\",\n",
    "        figsize=(6, 5),\n",
    "        normalize=True,\n",
    "        show_counts=True,\n",
    "        show_heatmap=True,\n",
    "        fmt=\"s\"\n",
    "    )\n",
    "\n",
    "    input(\"Press Enter to continue to the next model...\")\n",
    "\n",
    "print(\"\\n--- PCA, Decision Boundary, and Confusion Matrix Plotting Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
